{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools to use in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: fsspec in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (2.14.5)\n",
      "Requirement already satisfied: xxhash in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: pandas in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: multiprocess in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: packaging in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: filelock in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/pyxsis-usuario/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Size is 0.004254341125488281 MB\n",
      "content: ['Title: \"Artificial Intelligence and Its Impact on Society\"', '', 'Artificial Intelligence (AI) is a rapidly advancing field of computer science that has garnered significant attention in recent years. It refers to the development of computer systems that can perform tasks typically requiring human intelligence, such as problem-solving, decision-making, and learning from data. AI technologies, including machine learning, natural language processing, and computer vision, have the potential to revolutionize various aspects of our society, but they also come with their own set of challenges and ethical considerations.', '', 'One of the most prominent applications of AI is in healthcare. AI-powered diagnostic tools and predictive analytics have the potential to enhance early disease detection and improve treatment outcomes. For example, AI algorithms can analyze medical images, such as X-rays and MRIs, to detect abnormalities that might be missed by human radiologists. Additionally, AI can help healthcare providers manage patient data more effectively, leading to more personalized and efficient care.', '', 'In the realm of education, AI-driven platforms and chatbots are being used to provide personalized learning experiences to students. These systems can adapt to individual learning styles and pace, helping students grasp complex concepts more effectively. Furthermore, AI can automate administrative tasks, freeing up educators to focus on teaching and mentoring.', '', 'AI also plays a significant role in the business world. Companies are increasingly using AI for data analysis and decision-making. Machine learning algorithms can analyze vast amounts of data to identify trends, make predictions, and optimize supply chain management. Chatbots and virtual assistants are being employed for customer service and support, providing quicker responses to customer inquiries.', '', 'Autonomous vehicles are another area where AI is making strides. Self-driving cars rely on AI algorithms to perceive their environment, make real-time decisions, and navigate safely. While the potential benefits include reduced traffic accidents and increased mobility for people with disabilities, there are still regulatory and safety challenges to overcome.', '', 'AI is also transforming the field of entertainment. Streaming services use recommendation algorithms to suggest content based on user preferences, while video games employ AI to create dynamic and immersive gaming experiences. Creative AI tools are even assisting artists and musicians in generating new content and exploring innovative ideas.', '', 'However, as AI becomes more integrated into our daily lives, there are concerns about privacy and data security. AI systems often require access to vast amounts of personal data, raising questions about how that data is stored, used, and protected. Additionally, the potential for bias in AI algorithms, which can perpetuate discrimination, is a significant ethical concern that needs to be addressed.', '', 'Another critical issue is the impact of AI on the job market. While AI can automate routine and repetitive tasks, it also has the potential to create new jobs and opportunities in fields related to AI development, maintenance, and oversight. However, there may be a temporary disruption as some job roles become obsolete.', '', 'Ethical considerations surrounding AI include questions about accountability and transparency. When AI systems make decisions that affect individuals, it can be challenging to determine who is responsible for those decisions. Furthermore, understanding how AI algorithms arrive at their conclusions can be a complex and opaque process, which raises transparency concerns.', '', 'In the context of military and defense, AI-powered autonomous weapons raise ethical and legal questions about the use of lethal force without human intervention. The international community is actively debating the regulation and control of such technologies.', '', 'Overall, AI is poised to have a profound impact on society, with potential benefits in healthcare, education, business, transportation, entertainment, and more. However, it is essential to address the ethical, legal, and social implications of AI to ensure that its development and deployment align with our values and aspirations as a society. Policymakers, researchers, and industry leaders must work together to harness the potential of AI while mitigating its risks and ensuring that it benefits all members of society.']\n"
     ]
    }
   ],
   "source": [
    "file_name = \"./text.txt\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_name):\n",
    "    raise FileNotFoundError(f\"The file {file_name} does not exist.\")\n",
    "\n",
    "print(f'File Size is {os.stat(file_name).st_size / (1024 * 1024)} MB')\n",
    "\n",
    "txt_file = open(file_name, \"r\", encoding=\"utf-8\")\n",
    "content = txt_file.read()\n",
    "\n",
    "# Split the content into lines\n",
    "lines = content.splitlines()\n",
    "\n",
    "print(f'content: {lines}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Retriever\n",
    "\n",
    "This is a simple TF-IDF retriever that uses scikit-learn's TfidfVectorizer to index documents and sklearn's NearestNeighbors to do the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_documents(doc, max_doc_length=20):\n",
    "  # List containing full and segmented doc\n",
    "  segmented_docs = []\n",
    "\n",
    "  for lines in doc:\n",
    "    # Split document by spaces to obtain a word count that roughly approximates the token count\n",
    "    split_to_words = lines.split(\" \")\n",
    "\n",
    "    # If the document is longer than our maximum length, split it up into smaller segments and add them to the list \n",
    "    if len(split_to_words) > max_doc_length:\n",
    "      for doc_segment in range(0, len(split_to_words), max_doc_length):\n",
    "        segmented_docs.append( \" \".join(split_to_words[doc_segment:doc_segment + max_doc_length]))\n",
    "\n",
    "    # If the document is shorter than our maximum length, add it to the list\n",
    "    else:\n",
    "      segmented_docs.append(lines)\n",
    "\n",
    "  return segmented_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Relevant chunks\n",
    "\n",
    "The idea is to find the most relevant chunks of text in a document for a given query. The chunks are found by first splitting the document into sentences and then using the TF-IDF retriever to find the most relevant sentences. The chunks are then formed by concatenating the most relevant sentences together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_top_k_chunks(query, docs, k=2):\n",
    "\n",
    "  # Initialize a vectorizer that removes English stop words\n",
    "  vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words='english')\n",
    "\n",
    "  # Create a corpus of query and chunks and convert to TFIDF vectors\n",
    "  query_and_chunks = [query] + docs\n",
    "  matrix = vectorizer.fit_transform(query_and_chunks)\n",
    "\n",
    "  # Holds our cosine similarity scores\n",
    "  scores = []\n",
    "\n",
    "  # The first vector is our query text, so compute the similarity of our query against all chunks vectors\n",
    "  for i in range(1, len(query_and_chunks)):\n",
    "    scores.append(cosine_similarity(matrix[0], matrix[i])[0][0])\n",
    "\n",
    "  # Sort list of scores and return the top k highest scoring chunks\n",
    "  sorted_list = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "  top_doc_indices = [x[0] for x in sorted_list[:k]]\n",
    "  top_chunks = [docs[x] for x in top_doc_indices]\n",
    "  \n",
    "  return top_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-SQUAD Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll import a BERT model that has been fine-tuned on SQUAD, a task that asks the model to return the span of words most likely to contain the answer to a given question. This will serve as the reader component of our question answering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "\n",
    "    input_ids = tokenizer.encode(question, answer_text, max_length=512, truncation=True)\n",
    "    \n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    outputs = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                    token_type_ids=torch.tensor([segment_ids]), # The segment IDs to differentiate question from answer_text\n",
    "                    return_dict=True) \n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \"potential benefits\"\n",
      "Reference Document:  Overall, AI is poised to have a profound impact on society, with potential benefits in healthcare, education, business, transportation, entertainment, and more. However, it is essential to address the ethical, legal, and social implications of AI to ensure that its development and deployment align with our values and aspirations as a society. Policymakers, researchers, and industry leaders must work together to harness the potential of AI while mitigating its risks and ensuring that it benefits all members of society.\n",
      "Candidate chunks: ['Overall, AI is poised to have a profound impact on society, with potential benefits in healthcare, education, business, transportation, entertainment, and more. However, it is essential to address the ethical, legal, and social implications of AI to ensure that its development and deployment align with our values and aspirations as a society. Policymakers, researchers, and industry leaders must work together to harness the potential of AI while mitigating its risks and ensuring that it benefits all members of society.', 'One of the most prominent applications of AI is in healthcare. AI-powered diagnostic tools and predictive analytics have the potential to enhance early disease detection and improve treatment outcomes. For example, AI algorithms can analyze medical images, such as X-rays and MRIs, to detect abnormalities that might be missed by human radiologists. Additionally, AI can help healthcare providers manage patient data more effectively, leading to more personalized and efficient care.', 'AI is also transforming the field of entertainment. Streaming services use recommendation algorithms to suggest content based on user preferences, while video games employ AI to create dynamic and immersive gaming experiences. Creative AI tools are even assisting artists and musicians in generating new content and exploring innovative ideas.']\n",
      "Answer: \"more personalized and efficient care\"\n",
      "Reference Document:  One of the most prominent applications of AI is in healthcare. AI-powered diagnostic tools and predictive analytics have the potential to enhance early disease detection and improve treatment outcomes. For example, AI algorithms can analyze medical images, such as X-rays and MRIs, to detect abnormalities that might be missed by human radiologists. Additionally, AI can help healthcare providers manage patient data more effectively, leading to more personalized and efficient care.\n",
      "Candidate chunks: ['Overall, AI is poised to have a profound impact on society, with potential benefits in healthcare, education, business, transportation, entertainment, and more. However, it is essential to address the ethical, legal, and social implications of AI to ensure that its development and deployment align with our values and aspirations as a society. Policymakers, researchers, and industry leaders must work together to harness the potential of AI while mitigating its risks and ensuring that it benefits all members of society.', 'One of the most prominent applications of AI is in healthcare. AI-powered diagnostic tools and predictive analytics have the potential to enhance early disease detection and improve treatment outcomes. For example, AI algorithms can analyze medical images, such as X-rays and MRIs, to detect abnormalities that might be missed by human radiologists. Additionally, AI can help healthcare providers manage patient data more effectively, leading to more personalized and efficient care.', 'AI is also transforming the field of entertainment. Streaming services use recommendation algorithms to suggest content based on user preferences, while video games employ AI to create dynamic and immersive gaming experiences. Creative AI tools are even assisting artists and musicians in generating new content and exploring innovative ideas.']\n",
      "Answer: \"assisting\"\n",
      "Reference Document:  AI is also transforming the field of entertainment. Streaming services use recommendation algorithms to suggest content based on user preferences, while video games employ AI to create dynamic and immersive gaming experiences. Creative AI tools are even assisting artists and musicians in generating new content and exploring innovative ideas.\n",
      "Candidate chunks: ['Overall, AI is poised to have a profound impact on society, with potential benefits in healthcare, education, business, transportation, entertainment, and more. However, it is essential to address the ethical, legal, and social implications of AI to ensure that its development and deployment align with our values and aspirations as a society. Policymakers, researchers, and industry leaders must work together to harness the potential of AI while mitigating its risks and ensuring that it benefits all members of society.', 'One of the most prominent applications of AI is in healthcare. AI-powered diagnostic tools and predictive analytics have the potential to enhance early disease detection and improve treatment outcomes. For example, AI algorithms can analyze medical images, such as X-rays and MRIs, to detect abnormalities that might be missed by human radiologists. Additionally, AI can help healthcare providers manage patient data more effectively, leading to more personalized and efficient care.', 'AI is also transforming the field of entertainment. Streaming services use recommendation algorithms to suggest content based on user preferences, while video games employ AI to create dynamic and immersive gaming experiences. Creative AI tools are even assisting artists and musicians in generating new content and exploring innovative ideas.']\n"
     ]
    }
   ],
   "source": [
    "# Enter our query here\n",
    "query = \"How is AI being applied in the field of healthcare, and what benefits does it offer?\"\n",
    "#query = \"What ethical concerns are associated with the use of AI in decision-making processes, and how can they be addressed?\"\n",
    "#query = \"Can you explain the potential impact of AI on the job market, and what measures can be taken to mitigate job displacement?\"\n",
    "\n",
    "# Segment our documents\n",
    "segmented_docs = segment_documents(lines, 450)\n",
    "\n",
    "# Retrieve the top k most relevant documents to the query\n",
    "candidate_chunks = get_top_k_chunks(query, segmented_docs, 3)\n",
    "\n",
    "# Return the likeliest answers from each of our top k most relevant chunks in descending order\n",
    "for i in candidate_chunks:\n",
    "  answer_question(query, i)\n",
    "  print (\"Reference Document: \", i)\n",
    "  print(\"Candidate chunks:\", candidate_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
